{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#some imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#example with one audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n",
      "0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n",
      "1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n",
      "2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n",
      "3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n",
      "4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n",
      "\n",
      "              class  \n",
      "0          dog_bark  \n",
      "1  children_playing  \n",
      "2  children_playing  \n",
      "3  children_playing  \n",
      "4  children_playing  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#ex: load single audio file\\nexample_row = metadata.iloc[0]\\nfile_path = os.path.join(audio_folder,f\"fold{example_row[\\'fold\\']}\", example_row[\\'slice_file_name\\'])\\nlabel = example_row[\\'class\\']\\n\\n#load audio file\\ny, sr = librosa.load(file_path, sr = 22050) #resample to 22050 Hz\\nprint(f\"Audio file: {file_path}, Sample rate: {sr}, Duration: {len(y)/sr:.2f} seconds\")\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_path = 'c:/Users/leonor/desktop/ACII...folders/MCII-Project/UrbanSound8K/metadata/UrbanSound8K.csv'\n",
    "audio_folder = 'c:/Users/leonor/desktop/ACII...folders/MCII-Project/UrbanSound8K/audio'\n",
    "\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "print(metadata.head())\n",
    "\n",
    "\n",
    "'''#ex: load single audio file\n",
    "example_row = metadata.iloc[0]\n",
    "file_path = os.path.join(audio_folder,f\"fold{example_row['fold']}\", example_row['slice_file_name'])\n",
    "label = example_row['class']\n",
    "\n",
    "#loading audio file\n",
    "y, sr = librosa.load(file_path, sr = 22050) #resample to 22050 Hz\n",
    "print(f\"Audio file: {file_path}, Sample rate: {sr}, Duration: {len(y)/sr:.2f} seconds\")\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#pre-processing of all audio files\n",
    "#feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8732/8732 [05:22<00:00, 27.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature array shape: (8732, 128, 128)\n",
      "Labels array shape: (8732,)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm #to track progress\n",
    "\n",
    "def extract_features(metadata, audio_folder, fixed_length=128):\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    for _, row in tqdm(metadata.iterrows(), total=len(metadata)):\n",
    "        file_path = None #Initialize to avoid issues in the 'except' block\n",
    "        try:\n",
    "            #construct file path\n",
    "            file_path = os.path.join(audio_folder, f\"fold{row['fold']}\", row['slice_file_name'])\n",
    "            #File loading: It reads the audio file using librosa.load and converts the sound into a format your program understands (a waveform and its sample rate)\n",
    "            y, sr = librosa.load(file_path, sr=22050)\n",
    "            #adjust n_fft dynamically for short clips\n",
    "            n_fft = min(2048, len(y))\n",
    "            #compute mel-spectrogram\n",
    "            S = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=n_fft, hop_length=512, n_mels=128)\n",
    "            S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "            #ensure fixed-length feature by padding/truncating\n",
    "            if S_dB.shape[1]<fixed_length:\n",
    "                #ensure fixed length features\n",
    "                repeat_times = (fixed_length // S_dB.shape[1])+1\n",
    "                extended = np.tile(S_dB, (1,repeat_times))\n",
    "                features.append(extended[:, :fixed_length]) \n",
    "            else:\n",
    "                #truncate if too long\n",
    "                features.append(S_dB[:, :fixed_length])\n",
    "\n",
    "            labels.append(row['classID'])\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")\n",
    "    return features, labels\n",
    "\n",
    "#extract features and labels\n",
    "features, labels = extract_features(metadata, audio_folder)\n",
    "\n",
    "#convert to NumPy arrays for model compatibility\n",
    "x = np.array(features)\n",
    "y = np.array(labels)\n",
    "\n",
    "print(f\"Feature array shape: {x.shape}\")\n",
    "print(f\"Labels array shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#10-fold cross validation splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "def prepare_splits(x, y, metadata, n_splits=10):\n",
    "    group_kfold = GroupKFold(n_splits=n_splits)\n",
    "    groups = metadata['fold']\n",
    "    \n",
    "    for train_idx, test_idx in group_kfold.split(x, y, groups):\n",
    "        val_idx = train_idx[:len(train_idx)//10]  # Use 10% of training data for validation\n",
    "        train_idx = train_idx[len(train_idx)//10:]\n",
    "\n",
    "        x_train, x_val, x_test = x[train_idx], x[val_idx], x[test_idx]\n",
    "        y_train, y_val, y_test = y[train_idx], y[val_idx], y[test_idx]\n",
    "\n",
    "        yield x_train[..., np.newaxis], x_val[..., np.newaxis], x_test[..., np.newaxis], y_train, y_val, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#CNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leonor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,422,784</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m6,422,784\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m2,570\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,518,026</span> (24.86 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,518,026\u001b[0m (24.86 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,518,026</span> (24.86 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,518,026\u001b[0m (24.86 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def new_cnn_model(input_shape=(128,128,1), num_classes=10):\n",
    "    model =Sequential()\n",
    "\n",
    "    #1st conv + MaxPooling\n",
    "    model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    #2nd Conv + MaxPooling\n",
    "    model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    #3rd Conv + MaxPooling\n",
    "    model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    #Flattening\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #Fully connected layers\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    #Output layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    #Compile the model\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001), #Adaptive gradient optimizer\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "cnn_model = new_cnn_model()\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#simple supervised training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\\n\\n#training parameters\\nbatch_size = 32\\nepochs = 20\\n\\n#callbacks\\nearly_stopping = EarlyStopping(\\n    monitor=\\'val_loss\\', patience=5, restore_best_weights=True, verbose=1\\n)\\nreduce_lr = ReduceLROnPlateau(\\n    monitor=\\'val_loss\\', factor=0.5, patience=3, min_lr=1e-6, verbose=1\\n)\\n\\n#train model\\nhistory = cnn_model.fit(\\n    x_train, y_train,\\n    validation_data=(x_val,y_val),\\n    batch_size=batch_size,\\n    epochs=epochs,\\n    callbacks=[early_stopping, reduce_lr],\\n    verbose=1\\n)\\n\\n#evaluate model\\ntest_loss, test_accuracy = cnn_model.evaluate(x_test, y_test)\\nprint(f\"Test accuracy: {test_accuracy:.2f}, Test loss: {test_loss:.2f}\")'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#training parameters\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "\n",
    "#callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', patience=5, restore_best_weights=True, verbose=1\n",
    ")\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1\n",
    ")\n",
    "\n",
    "#train model\n",
    "history = cnn_model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_data=(x_val,y_val),\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "#evaluate model\n",
    "test_loss, test_accuracy = cnn_model.evaluate(x_test, y_test)\n",
    "print(f\"Test accuracy: {test_accuracy:.2f}, Test loss: {test_loss:.2f}\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#10-fold cross-validation with CNN implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leonor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 290ms/step - accuracy: 0.1129 - loss: 10.7524 - val_accuracy: 0.0711 - val_loss: 2.2571 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 286ms/step - accuracy: 0.1206 - loss: 2.2707 - val_accuracy: 0.0711 - val_loss: 2.2499 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 287ms/step - accuracy: 0.1232 - loss: 2.2648 - val_accuracy: 0.0891 - val_loss: 2.2504 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 287ms/step - accuracy: 0.1247 - loss: 2.2594 - val_accuracy: 0.0711 - val_loss: 2.2342 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 289ms/step - accuracy: 0.1674 - loss: 2.1849 - val_accuracy: 0.1240 - val_loss: 2.1137 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 292ms/step - accuracy: 0.2165 - loss: 2.0715 - val_accuracy: 0.1253 - val_loss: 2.0178 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 290ms/step - accuracy: 0.2859 - loss: 1.9175 - val_accuracy: 0.2558 - val_loss: 1.8818 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 289ms/step - accuracy: 0.4569 - loss: 1.5388 - val_accuracy: 0.2377 - val_loss: 1.9830 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 289ms/step - accuracy: 0.5689 - loss: 1.2661 - val_accuracy: 0.3915 - val_loss: 2.1689 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 301ms/step - accuracy: 0.6590 - loss: 1.0119 - val_accuracy: 0.5478 - val_loss: 1.5886 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 293ms/step - accuracy: 0.7250 - loss: 0.7932 - val_accuracy: 0.4742 - val_loss: 2.2435 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 288ms/step - accuracy: 0.7678 - loss: 0.6931 - val_accuracy: 0.4845 - val_loss: 2.5572 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.8082 - loss: 0.5877\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 291ms/step - accuracy: 0.8082 - loss: 0.5877 - val_accuracy: 0.4755 - val_loss: 3.0738 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 289ms/step - accuracy: 0.8532 - loss: 0.4453 - val_accuracy: 0.5349 - val_loss: 3.2092 - learning_rate: 5.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 293ms/step - accuracy: 0.8779 - loss: 0.3754 - val_accuracy: 0.5762 - val_loss: 3.1332 - learning_rate: 5.0000e-04\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Test accuracy: 0.57, Test loss: 1.28\n",
      "Epoch 1/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 291ms/step - accuracy: 0.1115 - loss: 10.3920 - val_accuracy: 0.0385 - val_loss: 2.2659 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 287ms/step - accuracy: 0.1214 - loss: 2.2670 - val_accuracy: 0.0385 - val_loss: 2.2583 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 290ms/step - accuracy: 0.1162 - loss: 2.2609 - val_accuracy: 0.0385 - val_loss: 2.2567 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 300ms/step - accuracy: 0.1195 - loss: 2.2616 - val_accuracy: 0.0385 - val_loss: 2.2553 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 300ms/step - accuracy: 0.1268 - loss: 2.2561 - val_accuracy: 0.0385 - val_loss: 2.2514 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 298ms/step - accuracy: 0.1234 - loss: 2.2547 - val_accuracy: 0.0385 - val_loss: 2.2479 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 296ms/step - accuracy: 0.1163 - loss: 2.2582 - val_accuracy: 0.0385 - val_loss: 2.2482 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 292ms/step - accuracy: 0.1174 - loss: 2.2600 - val_accuracy: 0.0385 - val_loss: 2.2543 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.1170 - loss: 2.2613\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 293ms/step - accuracy: 0.1170 - loss: 2.2612 - val_accuracy: 0.0385 - val_loss: 2.2565 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 295ms/step - accuracy: 0.1187 - loss: 2.2589 - val_accuracy: 0.0385 - val_loss: 2.2522 - learning_rate: 5.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 302ms/step - accuracy: 0.1192 - loss: 2.2587 - val_accuracy: 0.0385 - val_loss: 2.2497 - learning_rate: 5.0000e-04\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "Test accuracy: 0.11, Test loss: 2.31\n",
      "Epoch 1/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 297ms/step - accuracy: 0.1240 - loss: 9.1178 - val_accuracy: 0.0513 - val_loss: 2.2670 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 291ms/step - accuracy: 0.1207 - loss: 2.2711 - val_accuracy: 0.0513 - val_loss: 2.2471 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 292ms/step - accuracy: 0.1266 - loss: 2.2607 - val_accuracy: 0.0513 - val_loss: 2.2442 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 294ms/step - accuracy: 0.1322 - loss: 2.2531 - val_accuracy: 0.0718 - val_loss: 2.2378 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 292ms/step - accuracy: 0.1242 - loss: 2.2690 - val_accuracy: 0.0744 - val_loss: 2.2319 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 316ms/step - accuracy: 0.1265 - loss: 2.2614 - val_accuracy: 0.0513 - val_loss: 2.2376 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 381ms/step - accuracy: 0.1211 - loss: 2.2708 - val_accuracy: 0.0513 - val_loss: 2.2375 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 312ms/step - accuracy: 0.1182 - loss: 2.2663 - val_accuracy: 0.0513 - val_loss: 2.2315 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 351ms/step - accuracy: 0.1198 - loss: 2.2648 - val_accuracy: 0.0513 - val_loss: 2.2348 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 450ms/step - accuracy: 0.1177 - loss: 2.2663 - val_accuracy: 0.0513 - val_loss: 2.2383 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step - accuracy: 0.1145 - loss: 2.2636\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 345ms/step - accuracy: 0.1145 - loss: 2.2636 - val_accuracy: 0.0513 - val_loss: 2.2361 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 302ms/step - accuracy: 0.1176 - loss: 2.2684 - val_accuracy: 0.0513 - val_loss: 2.2363 - learning_rate: 5.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 311ms/step - accuracy: 0.1160 - loss: 2.2620 - val_accuracy: 0.0513 - val_loss: 2.2370 - learning_rate: 5.0000e-04\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "Test accuracy: 0.11, Test loss: 2.26\n",
      "Epoch 1/20\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 354ms/step - accuracy: 0.1096 - loss: 9.0520 - val_accuracy: 0.0651 - val_loss: 2.2605 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 355ms/step - accuracy: 0.1684 - loss: 2.2091 - val_accuracy: 0.4834 - val_loss: 1.6881 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 359ms/step - accuracy: 0.3825 - loss: 1.7295 - val_accuracy: 0.2972 - val_loss: 1.7795 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 357ms/step - accuracy: 0.5055 - loss: 1.3898 - val_accuracy: 0.3112 - val_loss: 1.8552 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346ms/step - accuracy: 0.6087 - loss: 1.1465\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 356ms/step - accuracy: 0.6088 - loss: 1.1463 - val_accuracy: 0.4681 - val_loss: 1.8911 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 365ms/step - accuracy: 0.7064 - loss: 0.8784 - val_accuracy: 0.5727 - val_loss: 1.4050 - learning_rate: 5.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 361ms/step - accuracy: 0.7747 - loss: 0.6691 - val_accuracy: 0.6173 - val_loss: 1.4467 - learning_rate: 5.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 361ms/step - accuracy: 0.8090 - loss: 0.5627 - val_accuracy: 0.6224 - val_loss: 1.3217 - learning_rate: 5.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 364ms/step - accuracy: 0.8301 - loss: 0.5164 - val_accuracy: 0.5804 - val_loss: 1.8460 - learning_rate: 5.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 364ms/step - accuracy: 0.8584 - loss: 0.4258 - val_accuracy: 0.6276 - val_loss: 1.2407 - learning_rate: 5.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 327ms/step - accuracy: 0.8849 - loss: 0.3522 - val_accuracy: 0.5906 - val_loss: 1.8454 - learning_rate: 5.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 347ms/step - accuracy: 0.8875 - loss: 0.3355 - val_accuracy: 0.6199 - val_loss: 1.7081 - learning_rate: 5.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step - accuracy: 0.9123 - loss: 0.2729\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 334ms/step - accuracy: 0.9123 - loss: 0.2729 - val_accuracy: 0.5829 - val_loss: 2.1904 - learning_rate: 5.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 334ms/step - accuracy: 0.9283 - loss: 0.2182 - val_accuracy: 0.6199 - val_loss: 2.5273 - learning_rate: 2.5000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m221/221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 391ms/step - accuracy: 0.9388 - loss: 0.1780 - val_accuracy: 0.6263 - val_loss: 2.0559 - learning_rate: 2.5000e-04\n",
      "Epoch 15: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "Test accuracy: 0.65, Test loss: 1.04\n",
      "Epoch 1/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 371ms/step - accuracy: 0.1186 - loss: 12.6857 - val_accuracy: 0.0561 - val_loss: 2.2437 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 313ms/step - accuracy: 0.1216 - loss: 2.2711 - val_accuracy: 0.0561 - val_loss: 2.2313 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 308ms/step - accuracy: 0.1115 - loss: 2.2695 - val_accuracy: 0.0561 - val_loss: 2.2260 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 298ms/step - accuracy: 0.1160 - loss: 2.2615 - val_accuracy: 0.0815 - val_loss: 2.2305 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 314ms/step - accuracy: 0.1213 - loss: 2.2685 - val_accuracy: 0.0561 - val_loss: 2.2245 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 295ms/step - accuracy: 0.1223 - loss: 2.2671 - val_accuracy: 0.0739 - val_loss: 2.2265 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 302ms/step - accuracy: 0.1139 - loss: 2.2681 - val_accuracy: 0.0561 - val_loss: 2.2245 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - accuracy: 0.1227 - loss: 2.2607\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 304ms/step - accuracy: 0.1227 - loss: 2.2607 - val_accuracy: 0.0739 - val_loss: 2.2259 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 305ms/step - accuracy: 0.1204 - loss: 2.2672 - val_accuracy: 0.0739 - val_loss: 2.2259 - learning_rate: 5.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 303ms/step - accuracy: 0.1115 - loss: 2.2681 - val_accuracy: 0.0561 - val_loss: 2.2258 - learning_rate: 5.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step - accuracy: 0.1181 - loss: 2.2681\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 350ms/step - accuracy: 0.1181 - loss: 2.2681 - val_accuracy: 0.0561 - val_loss: 2.2253 - learning_rate: 5.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 310ms/step - accuracy: 0.1226 - loss: 2.2636 - val_accuracy: 0.0561 - val_loss: 2.2261 - learning_rate: 2.5000e-04\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "Test accuracy: 0.11, Test loss: 2.25\n",
      "Epoch 1/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 332ms/step - accuracy: 0.1134 - loss: 9.2946 - val_accuracy: 0.0735 - val_loss: 2.2717 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 327ms/step - accuracy: 0.1121 - loss: 2.2718 - val_accuracy: 0.0621 - val_loss: 2.2447 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 328ms/step - accuracy: 0.1253 - loss: 2.2660 - val_accuracy: 0.0621 - val_loss: 2.2334 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 332ms/step - accuracy: 0.1151 - loss: 2.2693 - val_accuracy: 0.0621 - val_loss: 2.2380 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 349ms/step - accuracy: 0.1157 - loss: 2.2686 - val_accuracy: 0.0621 - val_loss: 2.2372 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step - accuracy: 0.1225 - loss: 2.2618\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 324ms/step - accuracy: 0.1225 - loss: 2.2618 - val_accuracy: 0.0621 - val_loss: 2.2339 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 350ms/step - accuracy: 0.1102 - loss: 2.2665 - val_accuracy: 0.0621 - val_loss: 2.2348 - learning_rate: 5.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 357ms/step - accuracy: 0.1145 - loss: 2.2649 - val_accuracy: 0.0621 - val_loss: 2.2361 - learning_rate: 5.0000e-04\n",
      "Epoch 8: early stopping\n",
      "Restoring model weights from the end of the best epoch: 3.\n",
      "Test accuracy: 0.12, Test loss: 2.27\n",
      "Epoch 1/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 376ms/step - accuracy: 0.1192 - loss: 8.6815 - val_accuracy: 0.3739 - val_loss: 1.8197 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 321ms/step - accuracy: 0.2816 - loss: 1.9800 - val_accuracy: 0.2915 - val_loss: 1.8352 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 229ms/step - accuracy: 0.4000 - loss: 1.6785 - val_accuracy: 0.3511 - val_loss: 1.8418 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - accuracy: 0.5166 - loss: 1.3902\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 254ms/step - accuracy: 0.5167 - loss: 1.3901 - val_accuracy: 0.3447 - val_loss: 2.2765 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 246ms/step - accuracy: 0.6161 - loss: 1.1194 - val_accuracy: 0.4918 - val_loss: 1.6501 - learning_rate: 5.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 245ms/step - accuracy: 0.6858 - loss: 0.9309 - val_accuracy: 0.5095 - val_loss: 1.6187 - learning_rate: 5.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 247ms/step - accuracy: 0.7315 - loss: 0.8066 - val_accuracy: 0.4867 - val_loss: 1.8785 - learning_rate: 5.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 270ms/step - accuracy: 0.7587 - loss: 0.7093 - val_accuracy: 0.5501 - val_loss: 1.6944 - learning_rate: 5.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 254ms/step - accuracy: 0.7938 - loss: 0.6118 - val_accuracy: 0.5817 - val_loss: 1.3977 - learning_rate: 5.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 272ms/step - accuracy: 0.8285 - loss: 0.5038 - val_accuracy: 0.5399 - val_loss: 1.6928 - learning_rate: 5.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 252ms/step - accuracy: 0.8206 - loss: 0.5565 - val_accuracy: 0.5539 - val_loss: 1.8810 - learning_rate: 5.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 0.8496 - loss: 0.4460\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 252ms/step - accuracy: 0.8496 - loss: 0.4459 - val_accuracy: 0.5539 - val_loss: 2.0623 - learning_rate: 5.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 243ms/step - accuracy: 0.8929 - loss: 0.3219 - val_accuracy: 0.6033 - val_loss: 1.9423 - learning_rate: 2.5000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 234ms/step - accuracy: 0.9058 - loss: 0.2850 - val_accuracy: 0.5526 - val_loss: 2.1864 - learning_rate: 2.5000e-04\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "Test accuracy: 0.71, Test loss: 0.96\n",
      "Epoch 1/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 237ms/step - accuracy: 0.1142 - loss: 11.6915 - val_accuracy: 0.0671 - val_loss: 2.2573 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 240ms/step - accuracy: 0.1242 - loss: 2.2710 - val_accuracy: 0.0595 - val_loss: 2.2335 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 232ms/step - accuracy: 0.1178 - loss: 2.2637 - val_accuracy: 0.0671 - val_loss: 2.2307 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 236ms/step - accuracy: 0.1228 - loss: 2.2645 - val_accuracy: 0.0671 - val_loss: 2.2286 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 245ms/step - accuracy: 0.1159 - loss: 2.2678 - val_accuracy: 0.0595 - val_loss: 2.2267 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 247ms/step - accuracy: 0.1215 - loss: 2.2652 - val_accuracy: 0.0671 - val_loss: 2.2302 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 248ms/step - accuracy: 0.1178 - loss: 2.2634 - val_accuracy: 0.0595 - val_loss: 2.2293 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.1153 - loss: 2.2679\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 235ms/step - accuracy: 0.1153 - loss: 2.2679 - val_accuracy: 0.1038 - val_loss: 2.2291 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 235ms/step - accuracy: 0.1204 - loss: 2.2646 - val_accuracy: 0.0595 - val_loss: 2.2290 - learning_rate: 5.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 233ms/step - accuracy: 0.1130 - loss: 2.2638 - val_accuracy: 0.0595 - val_loss: 2.2297 - learning_rate: 5.0000e-04\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Test accuracy: 0.12, Test loss: 2.26\n",
      "Epoch 1/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 239ms/step - accuracy: 0.1136 - loss: 11.3602 - val_accuracy: 0.0392 - val_loss: 2.2502 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 235ms/step - accuracy: 0.1184 - loss: 2.2678 - val_accuracy: 0.0910 - val_loss: 2.2090 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 242ms/step - accuracy: 0.1860 - loss: 2.1726 - val_accuracy: 0.2263 - val_loss: 1.9438 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 236ms/step - accuracy: 0.3201 - loss: 1.8990 - val_accuracy: 0.4248 - val_loss: 1.7074 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 238ms/step - accuracy: 0.4769 - loss: 1.4955 - val_accuracy: 0.5424 - val_loss: 1.5105 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 240ms/step - accuracy: 0.5730 - loss: 1.2566 - val_accuracy: 0.4665 - val_loss: 1.5409 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 237ms/step - accuracy: 0.6456 - loss: 1.0634 - val_accuracy: 0.5891 - val_loss: 1.3142 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 239ms/step - accuracy: 0.7081 - loss: 0.8981 - val_accuracy: 0.6043 - val_loss: 1.4627 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 237ms/step - accuracy: 0.7422 - loss: 0.8050 - val_accuracy: 0.6283 - val_loss: 1.3205 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - accuracy: 0.8020 - loss: 0.6207\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 304ms/step - accuracy: 0.8020 - loss: 0.6207 - val_accuracy: 0.5980 - val_loss: 1.3703 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 259ms/step - accuracy: 0.8371 - loss: 0.4929 - val_accuracy: 0.5954 - val_loss: 1.5700 - learning_rate: 5.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 256ms/step - accuracy: 0.8638 - loss: 0.4059 - val_accuracy: 0.7054 - val_loss: 1.1466 - learning_rate: 5.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 251ms/step - accuracy: 0.8742 - loss: 0.3766 - val_accuracy: 0.6738 - val_loss: 1.2230 - learning_rate: 5.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 253ms/step - accuracy: 0.8975 - loss: 0.3139 - val_accuracy: 0.6688 - val_loss: 1.4935 - learning_rate: 5.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 0.9082 - loss: 0.2809\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 243ms/step - accuracy: 0.9082 - loss: 0.2809 - val_accuracy: 0.6928 - val_loss: 1.3567 - learning_rate: 5.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 240ms/step - accuracy: 0.9133 - loss: 0.2624 - val_accuracy: 0.6903 - val_loss: 1.3681 - learning_rate: 2.5000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 241ms/step - accuracy: 0.9412 - loss: 0.1811 - val_accuracy: 0.6726 - val_loss: 1.3624 - learning_rate: 2.5000e-04\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "Test accuracy: 0.66, Test loss: 1.37\n",
      "Epoch 1/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 239ms/step - accuracy: 0.1093 - loss: 12.4319 - val_accuracy: 0.0795 - val_loss: 2.2630 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 242ms/step - accuracy: 0.1217 - loss: 2.2759 - val_accuracy: 0.0758 - val_loss: 2.2286 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 240ms/step - accuracy: 0.1105 - loss: 2.2696 - val_accuracy: 0.0732 - val_loss: 2.2176 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 237ms/step - accuracy: 0.1126 - loss: 2.2691 - val_accuracy: 0.0732 - val_loss: 2.2137 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 241ms/step - accuracy: 0.1164 - loss: 2.2706 - val_accuracy: 0.0732 - val_loss: 2.2156 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 244ms/step - accuracy: 0.1125 - loss: 2.2693 - val_accuracy: 0.0732 - val_loss: 2.2155 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 246ms/step - accuracy: 0.1064 - loss: 2.2681 - val_accuracy: 0.0732 - val_loss: 2.2134 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 243ms/step - accuracy: 0.1208 - loss: 2.2649 - val_accuracy: 0.0758 - val_loss: 2.2164 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 242ms/step - accuracy: 0.1071 - loss: 2.2723 - val_accuracy: 0.0732 - val_loss: 2.2149 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 0.1230 - loss: 2.2684\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 239ms/step - accuracy: 0.1229 - loss: 2.2684 - val_accuracy: 0.0758 - val_loss: 2.2143 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 239ms/step - accuracy: 0.1248 - loss: 2.2663 - val_accuracy: 0.0732 - val_loss: 2.2129 - learning_rate: 5.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 239ms/step - accuracy: 0.1124 - loss: 2.2622 - val_accuracy: 0.0732 - val_loss: 2.2152 - learning_rate: 5.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 239ms/step - accuracy: 0.1174 - loss: 2.2677 - val_accuracy: 0.0758 - val_loss: 2.2153 - learning_rate: 5.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 0.1092 - loss: 2.2674\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 238ms/step - accuracy: 0.1093 - loss: 2.2674 - val_accuracy: 0.0795 - val_loss: 2.2142 - learning_rate: 5.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 238ms/step - accuracy: 0.1278 - loss: 2.2657 - val_accuracy: 0.0795 - val_loss: 2.2138 - learning_rate: 2.5000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m223/223\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 238ms/step - accuracy: 0.1140 - loss: 2.2662 - val_accuracy: 0.0795 - val_loss: 2.2134 - learning_rate: 2.5000e-04\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "Test accuracy: 0.12, Test loss: 2.24\n",
      "Average Test Accuracy: 0.33\n",
      "Average Test Loss: 1.82\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n#previously defined folds from metadata\\nfolds = metadata['fold'].values\\nclass_labels = metadata['classID'].values\\n\\nfor test_fold in range(1,11):\\n    for val_fold in range(1,11):\\n        if val_fold == test_fold:\\n            continue\\n        #create train, test and val splits\\n        train_indices = metadata.index[~metadata['fold'].isin([test_fold, val_fold])].tolist()\\n        val_indices = metadata.index[metadata['fold'] == val_fold].tolist()\\n        test_indices = metadata.index[metadata['fold'] == test_fold].tolist()\\n\\n        x_train = x[train_indices]\\n        y_train = y[train_indices]\\n        x_val = x[val_indices]\\n        y_val = y[val_indices]\\n        x_test = x[test_indices]\\n        y_test = y[test_indices]\\n\\n        #CNN model\\n        model = Sequential([\\n            Conv2D(32,(3,3), activation='relu', input_shape=x_train.shape[1:]),\\n            MaxPooling2D(pool_size=(2,2)),\\n            Dropout(0.25),\\n            Conv2D(64,(3,3), activation='relu'),\\n            MaxPooling2D(pool_size=(2,2)),\\n            Dropout(0.25),\\n            Flatten(),\\n            Dense(128, activation='relu'),\\n            Dropout(0.5),\\n            Dense(len(np.unique(y)), activation='softmax')\\n        ])\\n\\n        #compile\\n        model.compile(\\n            optimizer=Adam(learning_rate=0.001),\\n            loss='sparse_categorical_crossentropy',\\n            metrics=['accuracy']\\n        )\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "#fold results\n",
    "fold_accuracies = []\n",
    "fold_losses = []\n",
    "\n",
    "for x_train, x_val, x_test, y_train, y_val, y_test in prepare_splits(x, y, metadata):\n",
    "    cnn_model = new_cnn_model(input_shape=(128, 128, 1), num_classes=len(np.unique(y)))\n",
    "\n",
    "       # Callbacks\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss', patience=5, restore_best_weights=True, verbose=1\n",
    "    )\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1\n",
    "    )\n",
    "\n",
    "    #training model\n",
    "    history = cnn_model.fit(\n",
    "        x_train, y_train,\n",
    "        validation_data=(x_val, y_val),\n",
    "        batch_size=32,\n",
    "        epochs=20,\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    #evatuation on the test set\n",
    "    test_loss, test_accuracy = cnn_model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(f\"Test accuracy: {test_accuracy:.2f}, Test loss: {test_loss:.2f}\")\n",
    "    fold_accuracies.append(test_accuracy)\n",
    "    fold_losses.append(test_loss)\n",
    "\n",
    "#averages\n",
    "average_accuracy = np.mean(fold_accuracies)\n",
    "average_loss = np.mean(fold_losses)\n",
    "\n",
    "print(f\"Average Test Accuracy: {average_accuracy:.2f}\")\n",
    "print(f\"Average Test Loss: {average_loss:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
